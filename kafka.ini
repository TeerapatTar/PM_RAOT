# ------------------------------------------------------------------------------------------------------------------------------------------------------------
# create random uuid for controller and broker
cluster_id=$(/home/kafka/bin/kafka-storage.sh random-uuid)
controller_1_uuid=$(/home/kafka/bin/kafka-storage.sh random-uuid)
controller_2_uuid=$(/home/kafka/bin/kafka-storage.sh random-uuid)
controller_3_uuid=$(/home/kafka/bin/kafka-storage.sh random-uuid)

cluster_id=rKcU6M5oTF-bR7FgtDHWDg
controller_1_uuid=Sc2_lUJcTIK0zRF5TYp7qw
controller_2_uuid=_mCKNwm6QMOukyZVfcH4ZQ
controller_3_uuid=1K7tQo8ARdKa9QPpf4SjBQ

# initial cluster controller and broker
/home/kafka/bin/kafka-storage.sh format --cluster-id $cluster_id --initial-controllers "1@controller1:9093:${controller_1_uuid},2@controller2:9093:${controller_2_uuid},3@controller3:9093:${controller_3_uuid}" --config /home/kafka/config/kraft/controller.properties
/opt/kafka/controller/bin/kafka-storage.sh format --cluster-id rKcU6M5oTF-bR7FgtDHWDg --initial-controllers "4@controller1:9093:Sc2_lUJcTIK0zRF5TYp7qw,5@controller2:9093:_mCKNwm6QMOukyZVfcH4ZQ,6@controller3:9093:1K7tQo8ARdKa9QPpf4SjBQ" --config /opt/kafka/controller/config/controller.properties

/home/kafka/bin/kafka-storage.sh format --cluster-id $cluster_id --config /home/kafka/config/kraft/broker.properties --no-initial-controllers
/opt/kafka/broker/bin/kafka-storage.sh format --cluster-id rKcU6M5oTF-bR7FgtDHWDg --config /opt/kafka/broker/config/broker.properties --no-initial-controllers


sudo chown -R kafka:kafka /var/lib/kraft/*
sudo chmod -R 700 /var/lib/kraft/*

# add controller and start to kraft storage
/home/kafka/bin/kafka-server-start.sh -daemon /home/kafka/config/kraft/controller.properties
kill -15 $(pgrep -f java)

# add broker and start to kraft storage
/home/kafka/bin/kafka-server-start.sh -daemon /home/kafka/config/kraft/broker.properties
kill -15 $(pgrep -f java)

# Verify broker and controller in storage
/opt/kafka/broker/bin/kafka-metadata-quorum.sh --bootstrap-controller controller1:9093,controller2:9093,controller3:9093 --command-config /opt/kafka/broker/config/client.properties describe --re --hu
/opt/kafka/broker/bin/kafka-metadata-quorum.sh --bootstrap-server  broker1:9092,broker2:9092,broker3:9092 --command-config /opt/kafka/broker/config/client.properties  describe --status


/opt/kafka/broker/bin/kafka-topics.sh  --bootstrap-server  broker1:9092,broker2:9092,broker3:9092 --command-config /opt/kafka/broker/config/client.properties --create --topic test --replication-factor 3 --partitions 6
/opt/kafka/broker/bin/kafka-topics.sh  --bootstrap-server  broker1:9092,broker2:9092,broker3:9092 --command-config /opt/kafka/broker/config/client.properties --list
/opt/kafka/broker/bin/kafka-topics.sh  --bootstrap-server  broker1:9092,broker2:9092,broker3:9092 --command-config /opt/kafka/broker/config/client.properties --describe --topic test
/opt/kafka/broker/bin/kafka-console-producer.sh  --bootstrap-server  broker1:9092,broker2:9092,broker3:9092 --producer.config /opt/kafka/broker/config/client.properties --topic test
/opt/kafka/broker/bin/kafka-console-consumer.sh  --bootstrap-server  broker1:9092,broker2:9092,broker3:9092 --consumer.config /opt/kafka/broker/config/client.properties --topic test --from-beginning
/opt/kafka/broker/bin/kafka-topics.sh --bootstrap-server broker1:9092,broker2:9092,broker3:9092 --topic __consumer_offsets --describe --command-config /opt/kafka/broker/config/client.properties
/opt/kafka/broker/bin/kafka-topics.sh --bootstrap-server broker1:9092,broker2:9092,broker3:9092 --topic __consumer_offsets --describe --command-config /opt/kafka/broker/config/client.properties >> /opt/kafka/consumer-offsets-topic
/opt/kafka/broker/bin/kafka-topics.sh --bootstrap-server broker1:9092,broker2:9092,broker3:9092 --topic test --describe --command-config /opt/kafka/broker/config/client.properties >> /opt/kafka/test-topic

# command for check broker on cluster 
/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server broker1.ttb.ekafka.local:9092,broker2.ttb.ekafka.local:9092 | awk '/id/{print $1}'
/opt/kafka/broker/bin/kafka-broker-api-versions.sh --bootstrap-server broker1:9092,broker2:9092,broker3:9092 --command-config /opt/kafka/broker/config/client.properties | awk '/id/{print $1}'

## broker config broker.properties
process.roles=broker
node.id=1
listeners=SASL_PLAINTEXT://broker1:9092
inter.broker.listener.name=SASL_PLAINTEXT
advertised.listeners=SASL_PLAINTEXT://broker1:9092
controller.listener.names=CONTROLLER
listener.security.protocol.map=SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:SASL_PLAINTEXT
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.partitions=8
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=1
share.coordinator.state.topic.replication.factor=3
share.coordinator.state.topic.min.isr=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
controller.quorum.bootstrap.servers=controller1:9093,controller2:9093,controller3:9093
log.dirs=/var/lib/kraft/kafka
sasl.enabled.mechanisms=PLAIN
sasl.mechanism.controller.protocol=PLAIN
sasl.mechanism.inter.broker.protocol=PLAIN
authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
super.users=User:admin
-------------------------------------------------------------------------
process.roles=broker
node.id=2
listeners=SASL_PLAINTEXT://broker2:9092
inter.broker.listener.name=SASL_PLAINTEXT
advertised.listeners=SASL_PLAINTEXT://broker2:9092
controller.listener.names=CONTROLLER
listener.security.protocol.map=SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:SASL_PLAINTEXT
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.partitions=8
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=1
share.coordinator.state.topic.replication.factor=3
share.coordinator.state.topic.min.isr=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
controller.quorum.bootstrap.servers=controller1:9093,controller2:9093,controller3:9093
log.dirs=/var/lib/kraft/kafka
sasl.enabled.mechanisms=PLAIN
sasl.mechanism.controller.protocol=PLAIN
sasl.mechanism.inter.broker.protocol=PLAIN
authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
super.users=User:admin

##controller config
process.roles=controller
node.id=4
controller.quorum.bootstrap.servers=controller1:9093,controller2:9093,controller3:9093
advertised.listeners=CONTROLLER://controller1:9093
listener.security.protocol.map=SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:SASL_PLAINTEXT
listeners=CONTROLLER://controller1:9093
controller.listener.names=CONTROLLER
log.dirs=/var/lib/kraft/controller
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.recovery.threads.per.data.dir=1
log.retention.hours=48
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
sasl.enabled.mechanisms=PLAIN
sasl.mechanism.controller.protocol=PLAIN
authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
super.users=User:admin
--------------------------------------------------------------
process.roles=controller
node.id=5
controller.quorum.bootstrap.servers=controller1:9093,controller2:9093,controller3:9093
advertised.listeners=CONTROLLER://controller2:9093
listener.security.protocol.map=SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:SASL_PLAINTEXT
listeners=CONTROLLER://controller2:9093
controller.listener.names=CONTROLLER
log.dirs=/var/lib/kraft/controller
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.recovery.threads.per.data.dir=1
log.retention.hours=48
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
sasl.enabled.mechanisms=PLAIN
sasl.mechanism.controller.protocol=PLAIN
authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
super.users=User:admin

## client config client.properties
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin";
security.protocol=SASL_PLAINTEXT
sasl.mechanism=PLAIN

## jaas config
KafkaServer {
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username="admin"
  password="admin"
  user_admin="admin";
};

# broker service start
[Unit]
Description=Apache Kafka server (broker)
Documentation=http://kafka.apache.org/documentation.html
Requires=network.target remote-fs.target
After=network.target remote-fs.target zookeeper.service

[Service]
Type=simple
User=kafka
Group=kafka
Environment=KAFKA_OPTS=-Djava.security.auth.login.config=/opt/kafka/jaas.conf
ExecStart=/opt/kafka/broker/bin/kafka-server-start.sh /opt/kafka/broker/config/broker.properties
ExecStop=/opt/kafka/broker/bin/kafka-server-stop.sh
LimitNOFILE=100000
Environment="KAFKA_HEAP_OPTS=-Xms4G -Xmx4G"

[Install]
WantedBy=multi-user.target


# controller service start
[Unit]
Description=Apache Kafka server (broker)
Documentation=http://kafka.apache.org/documentation.html
Requires=network.target remote-fs.target
After=network.target remote-fs.target zookeeper.service

[Service]
Type=simple
User=kafka
Group=kafka
Environment=KAFKA_OPTS=-Djava.security.auth.login.config=/opt/kafka/jaas.conf
ExecStart=/opt/kafka/controller/bin/kafka-server-start.sh /opt/kafka/controller/config/controller.properties
ExecStop=/opt/kafka/controller/bin/kafka-server-stop.sh

[Install]
WantedBy=multi-user.target


x.x.x.x controller1 broker1
x.x.x.x controller2 broker2
x.x.x.x controller3 broker3